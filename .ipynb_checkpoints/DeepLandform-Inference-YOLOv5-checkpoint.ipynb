{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLandforms Inference YOLOv5\n",
    "## Landforms Object Detection Inference and shapefile creation using YOLOv5\n",
    "@ g.nodjoumi@jacobs-university.de\n",
    "\n",
    "***This notebook is based on yolov5 repository is provided by ultralytics https://zenodo.org/record/4154370 that has been modified to adapt to landforms***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gnodj/W-DATS/python_scripts/DeepLearning/DeepLandforms-YOLOv5/yolov5\n",
      "torch 1.7.1 _CudaDeviceProperties(name='Quadro RTX 4000', major=7, minor=5, total_memory=7973MB, multi_processor_count=36)\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "import os\n",
    "from adds.GenUtils import question, get_types, get_paths, make_folder\n",
    "from adds.DLUtils import get_train_cfg, link_dataset, get_model_cfg, get_args\n",
    "from adds.inf2shp import df_comb, df2shp, copyfiles, get_world_file\n",
    "import torch\n",
    "from IPython.display import Image  # for displaying images\n",
    "\n",
    "print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = '/media/gnodj/W-DATS/python_scripts/DeepLearning/Skylight-DL/yolov5l-weights-skylights/weights/best_yolov5l_results.pt'\n",
    "#weights = input(str('Path to weights file'))\n",
    "#source = '/media/gnodj/W-DATS/HiRiSE_Data/test_'\n",
    "#source='/media/gnodj/W-DATS/HiRiSE_Data/ImageClassifier_test/test/tiff/sub'\n",
    "#source='/media/gnodj/W-DATS/HiRiSE_Data/ImageClassifier_test/test/tiff/sub/test'\n",
    "source ='/media/gnodj/W-DATS/HiRiSE_Data/test'\n",
    "output = source+'/output'\n",
    "#source = input(str('Path to source images'))\n",
    "img_size = 4096\n",
    "#img_size = int(input('Image size for scaling'))\n",
    "conf_thres = 0.5\n",
    "#conf_thres = float(input('Confidence threshold'))\n",
    "home = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary with all parameters\n",
    "***edit if necessary***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    '--weights': wts,\n",
    "    '--source':source,\n",
    "    '--img-size':img_size,\n",
    "    '--conf-thres':conf_thres,\n",
    "    '--iou-thres':0.4,\n",
    "    '--device':'',\n",
    "    '--view-img': '',\n",
    "    '--save-txt': True,\n",
    "    '--save-conf':True,\n",
    "    '--classes': '',\n",
    "    '--agnostic_nms':'',\n",
    "    '--augment':'',\n",
    "    '--update':'',\n",
    "    '--project':source,\n",
    "    '--name':'output',\n",
    "    '--exist-ok':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arv = get_args(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.5, device='', exist_ok=False, img_size=4096, iou_thres=0.4, name='output', project='/media/gnodj/W-DATS/HiRiSE_Data/test', save_conf=True, save_txt=True, source='/media/gnodj/W-DATS/HiRiSE_Data/test', update=False, view_img=False, weights=['/media/gnodj/W-DATS/python_scripts/DeepLearning/Skylight-DL/yolov5l-weights-skylights/weights/best_yolov5l_results.pt'])\n",
      "Using torch 1.7.1 CUDA:0 (Quadro RTX 4000, 7973.0MB)\n",
      "\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 400 layers, 47386202 parameters, 0 gradients\n",
      "image 1/2 /media/gnodj/W-DATS/HiRiSE_Data/test/ESP_011386_2065_RED_uint8.png: 4096x1824 1 1s, 3 4s, 17 5s, Done. (0.140s)\n",
      "image 2/2 /media/gnodj/W-DATS/HiRiSE_Data/test/ESP_021738_1625_RED_H0_V0.tiff: 4096x4096 Done. (0.306s)\n",
      "Results saved to /media/gnodj/W-DATS/HiRiSE_Data/test/output4\n",
      "1 labels saved to /media/gnodj/W-DATS/HiRiSE_Data/test/output4/labels\n",
      "Done. (3.324s)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(home)\n",
    "!python detect.py $arv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert detection to shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create list od detections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/gnodj/W-DATS/HiRiSE_Data/test/output/labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a644074cdf70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/gnodj/W-DATS/python_scripts/DeepLearning/DeepLandforms-YOLOv5/yolov5/adds/GenUtils.py\u001b[0m in \u001b[0;36mget_paths\u001b[0;34m(PATH, ixt)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mfnmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mixt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mchkCase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/gnodj/W-DATS/HiRiSE_Data/test/output/labels'"
     ]
    }
   ],
   "source": [
    "detections = get_paths(output+'/labels', 'txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESP_011386_2065_RED_uint8.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create final dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gnodj/W-DATS/HiRiSE_Data/test/output/ESP_011386_2065_RED_uint8.tiff\n"
     ]
    }
   ],
   "source": [
    "dataframe = df_comb(detections, 'tiff', source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save to shapefile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe  Folder not exist, creating.\n",
      "Created new  Dataframe  Folder\n"
     ]
    }
   ],
   "source": [
    "fname = make_folder(output, 'Dataframe')\n",
    "df2shp(fname, dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
