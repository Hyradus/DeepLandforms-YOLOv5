{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 3169 (delta 0), reused 0 (delta 0), pack-reused 3165\u001b[K\n",
      "Receiving objects: 100% (3169/3169), 6.45 MiB | 6.33 MiB/s, done.\n",
      "Resolving deltas: 100% (2115/2115), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -r yolov5/requirements.txt  # install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.7.0 _CudaDeviceProperties(name='Quadro RTX 4000', major=7, minor=5, total_memory=7973MB, multi_processor_count=36)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image  # for displaying images\n",
    "#from utils.google_utils import gdrive_download  # for downloading models/datasets\n",
    "\n",
    "print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://app.roboflow.com/ds/xb68Xgda3t?key=bS6Lz0M3lL\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "data = '../data.yaml'\n",
    "with open(data, 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters\n",
      "nc: 80  # number of classes\n",
      "depth_multiple: 0.33  # model depth multiple\n",
      "width_multiple: 0.50  # layer channel multiple\n",
      "\n",
      "# anchors\n",
      "anchors:\n",
      "  - [10,13, 16,30, 33,23]  # P3/8\n",
      "  - [30,61, 62,45, 59,119]  # P4/16\n",
      "  - [116,90, 156,198, 373,326]  # P5/32\n",
      "\n",
      "# YOLOv5 backbone\n",
      "backbone:\n",
      "  # [from, number, module, args]\n",
      "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
      "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
      "   [-1, 3, BottleneckCSP, [128]],\n",
      "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
      "   [-1, 9, BottleneckCSP, [256]],\n",
      "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
      "   [-1, 9, BottleneckCSP, [512]],\n",
      "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
      "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
      "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
      "  ]\n",
      "\n",
      "# YOLOv5 head\n",
      "head:\n",
      "  [[-1, 1, Conv, [512, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
      "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
      "\n",
      "   [-1, 1, Conv, [256, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
      "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
      "\n",
      "   [-1, 1, Conv, [256, 3, 2]],\n",
      "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
      "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
      "\n",
      "   [-1, 1, Conv, [512, 3, 2]],\n",
      "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
      "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
      "\n",
      "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
      "  ]\n"
     ]
    }
   ],
   "source": [
    "#%cd yolov5\n",
    "%cat models/yolov5s.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: {num_classes}  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/       hubconf.py  \u001b[01;34m__pycache__\u001b[0m/       test.py         \u001b[01;34mutils\u001b[0m/\n",
      "detect.py   LICENSE     \u001b[01;32mREADME.md\u001b[0m*         train.py        \u001b[01;34mweights\u001b[0m/\n",
      "Dockerfile  \u001b[01;34mmodels\u001b[0m/     \u001b[01;32mrequirements.txt\u001b[0m*  tutorial.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.7.0 CUDA:0 (Quadro RTX 4000, 7973MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=4, bucket='', cache_images=True, cfg='./models/custom_yolov5s.yaml', data='../data.yaml', device='', epochs=2000, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[900, 900], local_rank=-1, log_imgs=16, multi_scale=False, name='yolov5x_results', noautoanchor=False, nosave=False, notest=False, project='runs/train', rect=False, resume=False, save_dir='runs/train/yolov5x_results6', single_cls=False, sync_bn=False, total_batch_size=4, weights='', workers=8, world_size=1)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
      "Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     26970  models.yolo.Detect                      [5, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7265882 parameters, 7265882 gradients\n",
      "\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "WARNING: --img-size 900 must be multiple of max stride 32, updating to 928\n",
      "WARNING: --img-size 900 must be multiple of max stride 32, updating to 928\n",
      "Scanning '../train/labels.cache' for images and labels... 405 found, 0 missing, \n",
      "Caching images (1.0GB): 100%|████████████████| 405/405 [00:00<00:00, 675.74it/s]\n",
      "Scanning '../valid/labels.cache' for images and labels... 38 found, 0 missing, 0\n",
      "Caching images (0.1GB): 100%|██████████████████| 38/38 [00:00<00:00, 493.91it/s]\n",
      "\n",
      "Analyzing anchors... anchors/target = 5.38, Best Possible Recall (BPR) = 0.9821\n",
      "Image sizes 928 train, 928 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/yolov5x_results6\n",
      "Starting training for 2000 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "    0/1999     1.58G    0.1067    0.0296   0.05078     0.187        10       928\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all          38         128           0           0    0.000239    6.23e-05\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "    1/1999     1.69G   0.09666   0.02603   0.04868    0.1714         0       928\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all          38         128    0.000706      0.0615     0.00232    0.000458\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "    2/1999     1.69G   0.09259   0.02391   0.04754     0.164         9       928^C\n",
      "    2/1999     1.69G   0.09259   0.02391   0.04754     0.164         9       928\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 492, in <module>\n",
      "    train(hyp, opt, device, tb_writer, wandb)\n",
      "  File \"train.py\", line 297, in train\n",
      "    scaler.step(optimizer)  # optimizer.step\n",
      "  File \"/home/gnodj/anaconda3/envs/DL-pytorch-38/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\", line 321, in step\n",
      "    retval = optimizer.step(*args, **kwargs)\n",
      "  File \"/home/gnodj/anaconda3/envs/DL-pytorch-38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\", line 67, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/home/gnodj/anaconda3/envs/DL-pytorch-38/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/gnodj/anaconda3/envs/DL-pytorch-38/lib/python3.8/site-packages/torch/optim/sgd.py\", line 106, in step\n",
      "    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 900 --batch 4 --epochs 2000 --data ../data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5x_results  --cache-image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
